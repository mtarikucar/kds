version: '3.8'

name: kds-staging

services:
  # PostgreSQL Database (Shared - uses staging database)
  postgres:
    env_file:
      - .env.test
    image: postgres:15-alpine
    container_name: kds_postgres_staging
    restart: always
    environment:
      POSTGRES_DB: ${POSTGRES_DB:-restaurant_pos_staging}
      POSTGRES_USER: ${POSTGRES_USER:-postgres}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
    ports:
      - '5433:5432'
    volumes:
      - postgres_data_staging:/var/lib/postgresql/data
    healthcheck:
      test: ['CMD-SHELL', 'pg_isready -U postgres']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kds_staging_network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Redis Cache (Shared - uses DB 1 for staging)
  redis:
    env_file:
      - .env.test
    image: redis:7-alpine
    container_name: kds_redis_staging
    restart: always
    ports:
      - '6380:6379'
    volumes:
      - redis_data_staging:/data
    healthcheck:
      test: ['CMD', 'redis-cli', 'ping']
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - kds_staging_network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

  # Apache Kafka (KRaft mode - no Zookeeper)
  kafka:
    image: apache/kafka:3.7.0
    container_name: kds_kafka_staging
    restart: always
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_LISTENERS: 'CONTROLLER://kafka:29093,PLAINTEXT://kafka:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_NUM_PARTITIONS: 5
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      CLUSTER_ID: 'kds-kafka-staging-001'
    ports:
      - '9093:9092'
    volumes:
      - kafka_data_staging:/var/lib/kafka/data
    healthcheck:
      test: ['CMD-SHELL', '/opt/kafka/bin/kafka-topics.sh --bootstrap-server localhost:9092 --list || exit 1']
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    networks:
      - kds_staging_network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Kafka Topic Initialization
  kafka-init:
    image: apache/kafka:3.7.0
    container_name: kds_kafka_init_staging
    depends_on:
      kafka:
        condition: service_healthy
    entrypoint: ['/bin/sh', '-c']
    command: |
      "
      echo 'Waiting for Kafka to be ready...'
      sleep 5

      # Create topics for order integration
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic platform-webhooks --partitions 5 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic platform-webhooks-dlq --partitions 3 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic order-status-sync --partitions 3 --replication-factor 1
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --create --if-not-exists --topic order-status-sync-dlq --partitions 2 --replication-factor 1

      echo 'Topics created successfully!'
      /opt/kafka/bin/kafka-topics.sh --bootstrap-server kafka:9092 --list
      "
    networks:
      - kds_staging_network

  # Backend API (NestJS) - Staging
  backend:
    env_file:
      - .env.test
    image: ${BACKEND_IMAGE:-kds-staging-backend}
    build:
      context: ./backend
      dockerfile: Dockerfile
      target: production
    container_name: kds_backend_staging
    restart: always
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    environment:
      NODE_ENV: staging
      PORT: 3002
      POSTGRES_DB: restaurant_pos_staging
      DATABASE_URL: postgresql://${POSTGRES_USER:-postgres}:${POSTGRES_PASSWORD}@postgres:5432/restaurant_pos_staging
      REDIS_URL: redis://redis:6379/1
      JWT_SECRET: ${JWT_SECRET}
      JWT_EXPIRES_IN: ${JWT_EXPIRES_IN:-7d}
      JWT_REFRESH_SECRET: ${JWT_REFRESH_SECRET}
      JWT_REFRESH_EXPIRES_IN: ${JWT_REFRESH_EXPIRES_IN:-30d}
      CORS_ORIGIN: ${CORS_ORIGIN}
      # Stripe Configuration (Test Mode)
      STRIPE_SECRET_KEY: ${STRIPE_TEST_SECRET_KEY}
      STRIPE_PUBLISHABLE_KEY: ${STRIPE_TEST_PUBLISHABLE_KEY}
      STRIPE_WEBHOOK_SECRET: ${STRIPE_TEST_WEBHOOK_SECRET}
      # Iyzico Configuration (Sandbox)
      IYZICO_API_KEY: ${IYZICO_SANDBOX_API_KEY}
      IYZICO_SECRET_KEY: ${IYZICO_SANDBOX_SECRET_KEY}
      IYZICO_BASE_URL: ${IYZICO_BASE_URL:-https://sandbox-api.iyzipay.com}
      # PayTR Configuration (Test Mode)
      PAYTR_MERCHANT_ID: ${PAYTR_MERCHANT_ID}
      PAYTR_MERCHANT_KEY: ${PAYTR_MERCHANT_KEY}
      PAYTR_MERCHANT_SALT: ${PAYTR_MERCHANT_SALT}
      PAYTR_BASE_URL: ${PAYTR_BASE_URL:-https://www.paytr.com}
      PAYTR_TEST_MODE: ${PAYTR_TEST_MODE:-true}
      BACKEND_URL: ${BACKEND_URL:-https://staging.hummytummy.com}
      FRONTEND_URL: ${FRONTEND_URL:-https://staging.hummytummy.com}
      # Email Configuration
      EMAIL_HOST: ${EMAIL_HOST}
      EMAIL_PORT: ${EMAIL_PORT:-587}
      EMAIL_SECURE: ${EMAIL_SECURE:-false}
      EMAIL_USER: ${EMAIL_USER}
      EMAIL_PASSWORD: ${EMAIL_PASSWORD}
      EMAIL_FROM: ${EMAIL_FROM}
      # Subscription Settings
      DEFAULT_TRIAL_DAYS: ${DEFAULT_TRIAL_DAYS:-14}
      TRIAL_REMINDER_DAYS: ${TRIAL_REMINDER_DAYS:-3}
      # Google OAuth 2.0
      GOOGLE_CLIENT_ID: ${GOOGLE_CLIENT_ID}
      GOOGLE_CLIENT_SECRET: ${GOOGLE_CLIENT_SECRET}
      # Kafka Configuration
      KAFKA_BROKERS: kafka:9092
      KAFKA_CLIENT_ID: kds-order-integration-staging
      KAFKA_ENABLED: ${KAFKA_ENABLED:-true}
      USE_KAFKA_DLQ: ${USE_KAFKA_DLQ:-true}
    ports:
      - '3002:3002'
    volumes:
      - invoice_storage_staging:/app/storage
    healthcheck:
      test: ['CMD', 'curl', '-f', 'http://localhost:3002/api/health']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - kds_staging_network
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M

  # Frontend (React) - Staging
  frontend:
    env_file:
      - .env.test
    image: ${FRONTEND_IMAGE:-kds-staging-frontend}
    build:
      context: ./frontend
      dockerfile: Dockerfile
      target: production
      args:
        VITE_API_URL: ${VITE_API_URL:-https://staging.hummytummy.com/api}
        VITE_API_BASE_URL: ${VITE_API_BASE_URL:-https://staging.hummytummy.com}
        VITE_SOCKET_URL: ${VITE_SOCKET_URL:-https://staging.hummytummy.com}
        VITE_WS_URL: ${VITE_WS_URL:-wss://staging.hummytummy.com}
        VITE_STRIPE_PUBLISHABLE_KEY: ${VITE_STRIPE_PUBLISHABLE_KEY}
        VITE_GOOGLE_CLIENT_ID: ${VITE_GOOGLE_CLIENT_ID}
        VITE_APP_VERSION: ${VITE_APP_VERSION:-staging}
        VITE_BUILD_TIME: ${VITE_BUILD_TIME:-}
        VITE_COMMIT_SHA: ${VITE_COMMIT_SHA:-}
    container_name: kds_frontend_staging
    restart: always
    depends_on:
      - backend
    ports:
      - '5175:80'
    healthcheck:
      test: ['CMD', 'wget', '--spider', '-q', 'http://127.0.0.1:80']
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    networks:
      - kds_staging_network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M

volumes:
  postgres_data_staging:
  redis_data_staging:
  kafka_data_staging:
  invoice_storage_staging:

networks:
  kds_staging_network:
    driver: bridge
